{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I - The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/leand/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95b82a68f1b246ad9dadf79a950a10f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import get_dataset_split_names\n",
    "from datasets import load_dataset\n",
    "from datasets import dataset_dict\n",
    "from datasets import arrow_dataset\n",
    "import string\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - How many splits does the dataset has ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(get_dataset_split_names(\"imdb\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataset contient 3 splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - How big are thes splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 25000\n    })\n    unsupervised: Dataset({\n        features: ['text', 'label'],\n        num_rows: 50000\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le split train contient 25000 colonnes.\n",
    "Le split test contient 25000 colonnes.\n",
    "Le split unsupervised contient 50000 colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - What is the proportion of each class on the supervised splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "25000"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dataset[\"train\"][\"label\"]) + sum(dataset[\"test\"][\"label\"]) #count of supervised documents with positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "50000"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"train\"]) + len(dataset[\"test\"]) #count of supervised documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.5"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(dataset[\"train\"][\"label\"]) + sum(dataset[\"test\"][\"label\"])) / (len(dataset[\"train\"]) + len(dataset[\"test\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proportion de la classe positive est de 50%. Par conséquent, celle de la classe négative est également de 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II - Naive Bayes Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data : dict) -> dict:\n",
    "    '''Takes a document from a dataset, lowers the letters and\n",
    "    replace all punctuations by spaces'''\n",
    "    text = data[\"text\"]\n",
    "    for character in string.punctuation:\n",
    "        if character != \"-\":\n",
    "          text = text.replace(character, ' ')\n",
    "    data[\"text\"] = text.lower()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\leand\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-f89e94e326134889.arrow\n",
      "Loading cached processed dataset at C:\\Users\\leand\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-7e3b8c0cbea40c78.arrow\n",
      "Loading cached processed dataset at C:\\Users\\leand\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-9207d596dc166142.arrow\n"
     ]
    }
   ],
   "source": [
    "updated_dataset = dataset.map(preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Naive Bayes classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary_string(Vocabulary : dict[int], text : string, text_category : int, Categories : set[int]) -> dict[int]:\n",
    "    '''Updates the Vocabulary by adding the words contained in the text'''\n",
    "    for word in text.split():\n",
    "        if not (word in Vocabulary) :\n",
    "            Vocabulary[word] = {}\n",
    "            for category in Categories:\n",
    "                Vocabulary[word][category] = 0\n",
    "        Vocabulary[word][text_category] += 1\n",
    "    return Vocabulary\n",
    "\n",
    "def build_vocabulary(dataset : dataset_dict.DatasetDict, Categories : set[int]) -> dict[int]:\n",
    "    '''Construct a vocabulary from the documents contained in dataset'''\n",
    "    Vocabulary = {}\n",
    "    for document in dataset:\n",
    "        Vocabulary = build_vocabulary_string(Vocabulary, document[\"text\"], document[\"label\"], Categories)\n",
    "    return Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def train_naive_bayes(dataset : dataset_dict.DatasetDict, Categories : set[int]) -> tuple[dict[int], dict[dict[float]], dict[int]]:\n",
    "    '''Make a naive bayes training over the dataset and returns the logprior, the loglikelihood and the vocabulary produced'''\n",
    "    logprior = {}\n",
    "    loglikelihood = {}\n",
    "    documents_number = len(dataset)\n",
    "    Vocabulary = build_vocabulary(dataset, Categories)\n",
    "    for word in Vocabulary:\n",
    "        loglikelihood[word] = {}\n",
    "    for category in Categories:\n",
    "        documents_number_category = 0\n",
    "        for document in dataset:\n",
    "            if document[\"label\"] == category :\n",
    "                documents_number_category += 1\n",
    "        logprior[category] = math.log(documents_number_category / documents_number)\n",
    "        word_number = 0\n",
    "        for word in Vocabulary:\n",
    "            word_number += Vocabulary[word][category] + 1\n",
    "        for word in Vocabulary:\n",
    "            loglikelihood[word][category] = math.log((Vocabulary[word][category] + 1)/word_number)\n",
    "    return logprior, loglikelihood, Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(logprior, loglikelihood, Vocabulary) = train_naive_bayes(updated_dataset[\"train\"], {0, 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(text : string, logprior : dict[int], loglikelihood : dict[dict[float]], Categories : set[int], Vocabulary : dict[int]) -> int:\n",
    "    '''Estimates the category of the text from the logprior, the loglikelihood\n",
    "    and the vocabulary built through the training'''\n",
    "    sum = {}\n",
    "    for category in Categories:\n",
    "        sum[category] = logprior[category]\n",
    "        for word in text.split():\n",
    "            if word in Vocabulary:\n",
    "                sum[category] += loglikelihood[word][category]\n",
    "    return max(sum, key=sum.get)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Naive Bayes classifier using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return\n",
    "    def fit(self, X : arrow_dataset.Dataset, y:list[int] = None):\n",
    "        return self\n",
    "    def transform(self, X : arrow_dataset.Dataset) -> dataset_dict.DatasetDict:\n",
    "        '''Applies the preprocess function over the documents of the dataset X, then returns the texts of X'''\n",
    "        X_transformed = X.map(preprocess)\n",
    "        return X_transformed[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaiveBayesPipe = Pipeline([(\"PreProcessing\", PreProcessing()), (\"CountVectorization\", CountVectorizer()), (\"Naive Bayes Classifier\", MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\leand\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-f89e94e326134889.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('PreProcessing', PreProcessing()),\n                ('CountVectorization', CountVectorizer()),\n                ('Naive Bayes Classifier', MultinomialNB())])",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;PreProcessing&#x27;, PreProcessing()),\n                (&#x27;CountVectorization&#x27;, CountVectorizer()),\n                (&#x27;Naive Bayes Classifier&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;PreProcessing&#x27;, PreProcessing()),\n                (&#x27;CountVectorization&#x27;, CountVectorizer()),\n                (&#x27;Naive Bayes Classifier&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PreProcessing</label><div class=\"sk-toggleable__content\"><pre>PreProcessing()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBayesPipe.fit(dataset[\"train\"], dataset[\"train\"][\"label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Accuracy on both training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_good_answers(dataset : arrow_dataset.Dataset) -> int:\n",
    "    '''Count the number of good answers by applying the self-made naive bayes test function over all the documents of dataset'''\n",
    "    good_answers_test = 0\n",
    "    for document in dataset:\n",
    "        if test_naive_bayes(document[\"text\"], logprior, loglikelihood, {0, 1}, Vocabulary) == document[\"label\"] :\n",
    "            good_answers_test += 1\n",
    "    return good_answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set for self-made naive bayes implementation: \n",
      "0.81204\n",
      "Accuracy on training set for self-made naive bayes implementation: \n",
      "0.90612\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test set for self-made naive bayes implementation: \")\n",
    "print(count_good_answers(updated_dataset[\"test\"])/len(updated_dataset[\"test\"]))\n",
    "print(\"Accuracy on training set for self-made naive bayes implementation: \")\n",
    "print(count_good_answers(updated_dataset[\"train\"])/len(updated_dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\leand\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-f89e94e326134889.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set with scikit-learn: \n"
     ]
    },
    {
     "data": {
      "text/plain": "0.89808"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on training set with scikit-learn: \")\n",
    "NaiveBayesPipe.score(dataset[\"train\"], dataset[\"train\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\leand\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-7e3b8c0cbea40c78.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set with scikit-learn: \n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8136"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy on test set with scikit-learn: \")\n",
    "NaiveBayesPipe.score(dataset[\"test\"], dataset[\"test\"][\"label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- Why does the scikit-learn implementation give better results ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La différence de résultats peut s'expliquer par le fait que MultinomialNB utilise directement des flottants plutôt que des entiers, ce qui permet d'avoir des résultats plus proches lors des calculs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6- Why is the accurary a sufficient measure of evaluation here ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy est un moyen suffisant d'évaluation puisqu'il permet d'avoir les proportions de bonnes et de mauvaises réponses du modèle, et que l'on dispose d'un dataset important."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7- 2 wrongly classifier example from the test set and explanation of why the model failed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 1:\n",
      "blind date  columbia pictures  1934   was a decent film  but i have a few issues with this film. first of all  i don t fault the actors in this film at all  but more or less  i have a problem with the script. also  i understand that this film was made in the 1930 s and people were looking to escape reality  but the script made ann sothern s character look weak. she kept going back and forth between suitors and i felt as though she should have stayed with paul kelly s character in the end. he truly did care about her and her family and would have done anything for her and he did by giving her up in the end to fickle neil hamilton who in my opinion was only out for a good time. paul kelly s character  although a workaholic was a man of integrity and truly loved kitty  ann sothern  as opposed to neil hamilton  while he did like her a lot  i didn t see the depth of love that he had for her character. the production values were great  but the script could have used a little work.\n",
      "Good value :\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Error 2:\n",
      "ben   rupert grint   is a deeply unhappy adolescent  the son of his unhappily married parents. his father   nicholas farrell   is a vicar and his mother   laura linney   is ... well  let s just say she s a somewhat hypocritical soldier in jesus  army. it s only when he takes a summer job as an assistant to a foul mouthed  eccentric  once famous and now forgotten actress evie walton   julie walters   that he finally finds himself in true  harold and maude  fashion. of course  evie is deeply unhappy herself and it s only when these two sad sacks find each other that they can put their mutual misery aside and hit the road to happiness. br    br   of course it s corny and sentimental and very predictable but it has a hard side to it  too and walters  who could sleep walk her way through this sort of thing if she wanted  is excellent. it s when she puts the craziness to one side and finds the pathos in the character   like hitting the bottle and throwing up in the sink   that she s at her best. the problem is she s the only interesting character in the film  and it s not because of the script which doesn t do anybody any favours . grint  on the other hand  isn t just unhappy  he s a bit of a bore as well while linney s starched bitch is completely one dimensional.  still  she s got the english accent off pat . the best that can be said for it is that it s mildly enjoyable   with the emphasis on the mildly.\n",
      "Good value :\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "for document in updated_dataset[\"test\"]:\n",
    "    if found < 2:\n",
    "        if test_naive_bayes(document[\"text\"], logprior, loglikelihood, {0, 1},  Vocabulary) != document[\"label\"] :\n",
    "            found += 1\n",
    "            print(\"Error \" + str(found) + \":\")\n",
    "            print(document[\"text\"])\n",
    "            print(\"Good value :\")\n",
    "            print(document[\"label\"])\n",
    "            if found == 1 :\n",
    "                print(\"\\n\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le premier document, l'auteur a indiqué que le film n'était pas terrible, mais a voulu nuancer son propos ; par conséquent, une bonne partie du texte comprend des points positifs du film, ce qui a fausse le resultat.\n",
    "\n",
    "Dans le second document, on retrouve le meme probleme, avec certains mots employés (\"excellent\", \"best\", \"interesting\", \"enjoyable\") qui s'apparentent beaucoup plus au vocabulaire positif qu'au vocabulaire négatif, bien qu'éventuellement utilisés avec de la négation ou des nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III - Stemming and Lemmatization "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Adding stemming to pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\leand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "\n",
    "\n",
    "def preprocess_stemming(data : dict) -> dict:\n",
    "    '''Applies preprocess function coupled with stemming technique over the text of the document data'''\n",
    "    updated_data = preprocess(data)\n",
    "    re_word = re.compile(r\"^\\w+$\")\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for word in word_tokenize(updated_data[\"text\"].lower()) if re_word.match(word)]\n",
    "    updated_data[\"text\"] = \" \".join(stemmed)\n",
    "    return updated_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Train and evaluate the model again with these pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36d22a5a0c96483f9a140dfb70d009ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48b8a4e9fce64598a4611d618617f8cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2c03744ac2547359cc64d6df36dce60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_dataset_stem = dataset.map(preprocess_stemming)\n",
    "(logprior_stem, loglikelihood_stem, Vocabulary_stem) = train_naive_bayes(updated_dataset_stem[\"train\"], {0, 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set with stemming: \n",
      "0.8406\n",
      "Accuracy on test set with stemming: \n",
      "0.75324\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set with stemming: \")\n",
    "print(count_good_answers(updated_dataset_stem[\"train\"])/len(updated_dataset_stem[\"train\"]))\n",
    "print(\"Accuracy on test set with stemming: \")\n",
    "print(count_good_answers(updated_dataset_stem[\"test\"])/len(updated_dataset_stem[\"test\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Are the results better or worse ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont moins bons. Cela pourrait s'expliquer par le principe du stemming qui vise à garder la racine du mot, c'est à dire de tronquer toute déclinaison, accords et dérivation.\n",
    "\n",
    "Certains mots peuvent donc avoir une racine lui donnant une nuance plus positive ou négative selon le contexte, et cette nuance disparaît avec le stemming, qui peut donc amener à des estimations de mots plus \"neutres\", avec donc moins de mots déterminants, d'où une incertitude plus importante dans les résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
